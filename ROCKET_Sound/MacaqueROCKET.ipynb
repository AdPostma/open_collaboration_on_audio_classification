{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Created by Ignacio Oguiza - email: oguiza@gmail.com\n",
    "\n",
    "Modified by @pomo (Malcolm McLean) to handle variable length timeseries\n",
    "\n",
    "This version posted 20200405"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to diagnose a CUDA error...\n",
    "# from os import environ\n",
    "# environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T01:25:24.354653Z",
     "start_time": "2019-11-28T01:25:24.140536Z"
    },
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch: 1.4.0\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda'\n",
    "from ROCKETfuncs.ROCKETSound1 import *\n",
    "from sklearn.linear_model import RidgeClassifierCV\n",
    "print('pytorch:', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from os import path\n",
    "HOME = pathlib.Path(path.expanduser(\"~\"))\n",
    "DATA = pathlib.Path('data')\n",
    "from IPython.display import Audio # Audio(wav_files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T01:25:25.502236Z",
     "start_time": "2019-11-28T01:25:25.190801Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#My own utility for staying oriented!\n",
    "from myUtils.showType import ShowType\n",
    "t = ShowType().type_str\n",
    "from IPython.display import display, HTML, clear_output\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1️⃣ Generate features\n",
    "\n",
    "First you prepare the input data and normalize it per sample. The input to ROCKET Pytorch is a 3d tensor (preferrable on gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ndarray[7285]<object>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load Macaque calls and name that were saved in a different notebook...\n",
    "callArray = np.load(HOME/'.fastai/data/macaques_24414Hz/callArray.npy', allow_pickle=True) #This half-baked interpreter won't use ~ for Home.\n",
    "t(callArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ndarray[7285]<<U2>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nameArray = np.load(HOME/'.fastai/data/macaques_24414Hz/nameArray.npy', allow_pickle=True)\n",
    "t(nameArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize waveforms to mean 0, std 1\n",
    "def npM0S1(x):\n",
    "    return (x-x.mean())/(x.std())  #No /0 danger for these samples: min([c.std() for c in callArray])\n",
    "\n",
    "for i,x in enumerate(callArray):\n",
    "    callArray[i] = npM0S1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Take a look at the distribution of sample lengths...\n",
    "_=plt.hist(([len(x) for x in callArray]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place calls in array, padded with nan on right, sized to the longest sample.\n",
    "outarr=np.zeros((np.max([len(ps) for ps in callArray]),len(callArray)), dtype=np.float32)*np.nan \n",
    "for i,c in enumerate(callArray):  #populate columns\n",
    "    outarr[:len(c),i]=c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensor(cpu)[7285, 1, 41307]<float32>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Format samples for nn.conv1d...\n",
    "tcalls = torch.tensor(outarr).transpose(0,1).unsqueeze(1)\n",
    "t(tcalls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Uncomment this cell to cut down to a small number of samples for testing.\n",
    "\n",
    "# ncut = 500  #Use this many samples.\n",
    "\n",
    "# ndx = torch.randperm(len(tcalls)).tolist()\n",
    "# tcalls = tcalls[ndx]\n",
    "# tcalls = tcalls[:ncut]\n",
    "\n",
    "# nameArray = nameArray[ndx]\n",
    "# nameArray = nameArray[:ncut]\n",
    "# t(tcalls),t(nameArray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Tensor(cuda:0)[5828, 1, 41307]<float32>',\n",
       " 'Tensor(cuda:0)[1457, 1, 41307]<float32>',\n",
       " 'ndarray[5828]<<U2>',\n",
       " 'ndarray[1457]<<U2>')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Randomize, split into training and validation sets, load audio samples to device.\n",
    "trainFrac = .8\n",
    "nt = int(trainFrac*len(tcalls))\n",
    "\n",
    "indices = torch.randperm(len(tcalls)).tolist()\n",
    "X_train = tcalls[indices][:nt,:,:].to(device)\n",
    "X_valid = tcalls[indices][nt:,:,:].to(device)\n",
    "\n",
    "y_train = nameArray[indices][:nt]\n",
    "y_valid = nameArray[indices][nt:]\n",
    "\n",
    "t(X_train),t(X_valid),t(y_train),t(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort input and target ascending by length of audio. \n",
    "#This greatly speeds up the generation of ROCKET features (see below).\n",
    "def sortSet(inp,target):\n",
    "    lengths = torch.isfinite(inp).sum(dim=-1).squeeze() #Number of non-nans is the sample length\n",
    "    sortIndex = lengths.argsort()   \n",
    "    return inp[sortIndex],target[sortIndex.cpu()]\n",
    "\n",
    "X_train,y_train = sortSet(X_train,y_train)\n",
    "X_valid,y_valid = sortSet(X_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save in case we want to reproduce this train/val split\n",
    "torch.save(X_train,DATA/'X_train')\n",
    "torch.save(y_train,DATA/'y_train')\n",
    "torch.save(X_valid,DATA/'X_valid')\n",
    "torch.save(y_valid,DATA/'y_valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kernels=1000    #10000 is typical. 1000 performs a bit worse but is 10x faster to calculate.\n",
    "kss=[7, 9, 11]\n",
    "nfeatures = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There's a choice here. \n",
    "# 1) Tell ROCKET that the sequence length is as long as the longest call. \n",
    "# Then it generates conv1d's with large dilations that will be truncated or empty for shorter samples.\n",
    "# I think this means that ROCKET will not see low-frequency patterns.\n",
    "\n",
    "# 2) Tell ROCKET the sequence length is as long as the shortest sample. In this case, dilations are smaller, and low frequencies may be invisible.\n",
    "# But the features calculate much faster, and nn.conv1d stops throwing exception that have to be caught.\n",
    "# In actual testing, #2 does just as well or better.\n",
    "\n",
    "# seq_len = X_train.shape[2]  # 1)\n",
    "seq_len = min(torch.isfinite(X_train).sum(dim=-1).squeeze().min(),torch.isfinite(X_valid).sum(dim=-1).squeeze().min()).item()  #2)\n",
    "\n",
    "#N.B. When #1 is chosen, default values must be used when the sample is too short for a conv1d to return any values.\n",
    "#The particular choice of these defaults seems to affect accuracy.\n",
    "#When #2 is chosen, the conv1d's can handle all samples. The default values do not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = ROCKET(nfeatures, seq_len, n_kernels=n_kernels, kss=kss).to(device)  #Generate conv1d's\n",
    "\n",
    "#Let's plot bias and dilation distributions...\n",
    "dilations = [c.dilation[0] for c in model.convs]\n",
    "biases = [c.bias.data.item() for c in model.convs]\n",
    "plt.hist(biases)\n",
    "plt.title('Bias Distribution')\n",
    "plt.show()\n",
    "plt.hist(dilations)\n",
    "_ = plt.title('Dilation Distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate ROCKET features from the samples.\n",
    "#Use smaller batches to prevent CUDA out of memory.\n",
    "\n",
    "bs = 500\n",
    "\n",
    "def makeTfm(da,bs):\n",
    "#we assume that da is sorted by sample length ascending!\n",
    "\n",
    "    nBatches = (len(da)//bs)+1\n",
    "    for bi in range(nBatches):\n",
    "        end = min(bi*bs+bs,len(da))\n",
    "        batch = da[bi*bs:end] \n",
    "        if len(batch)==0:\n",
    "            break;\n",
    "\n",
    "        maxlength = torch.isfinite(batch[-1,0,:]).sum()  #Max length of the samples in this batch is length of the last sample\n",
    "        \n",
    "        bp = batch[:,:,:maxlength]                       #Process the shortest possible batch length to save time\n",
    "        print(bi+1,'/',nBatches,'  batch =',t(bp))\n",
    "        btfm = model(bp)           \n",
    "        if (bi==0):\n",
    "            tfm = btfm\n",
    "        else:\n",
    "            tfm = torch.cat((tfm,btfm), 0) \n",
    "    return tfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 12   batch = Tensor(cuda:0)[500, 1, 2695]<float32>\n",
      "2 / 12   batch = Tensor(cuda:0)[500, 1, 3471]<float32>\n",
      "3 / 12   batch = Tensor(cuda:0)[500, 1, 4226]<float32>\n",
      "4 / 12   batch = Tensor(cuda:0)[500, 1, 5274]<float32>\n",
      "5 / 12   batch = Tensor(cuda:0)[500, 1, 6721]<float32>\n",
      "6 / 12   batch = Tensor(cuda:0)[500, 1, 8117]<float32>\n",
      "7 / 12   batch = Tensor(cuda:0)[500, 1, 9580]<float32>\n",
      "8 / 12   batch = Tensor(cuda:0)[500, 1, 11195]<float32>\n",
      "9 / 12   batch = Tensor(cuda:0)[500, 1, 12872]<float32>\n",
      "10 / 12   batch = Tensor(cuda:0)[500, 1, 14477]<float32>\n",
      "11 / 12   batch = Tensor(cuda:0)[500, 1, 16421]<float32>\n",
      "12 / 12   batch = Tensor(cuda:0)[328, 1, 41307]<float32>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tensor(cuda:0)[5828, 2000]<float32>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfm = makeTfm(X_train,bs)\n",
    "t(X_train_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 / 3   batch = Tensor(cuda:0)[500, 1, 5464]<float32>\n",
      "2 / 3   batch = Tensor(cuda:0)[500, 1, 11119]<float32>\n",
      "3 / 3   batch = Tensor(cuda:0)[457, 1, 35020]<float32>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Tensor(cuda:0)[1457, 2000]<float32>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_tfm = makeTfm(X_valid,bs)\n",
    "t(X_valid_tfm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Any nans or infs among the features? Success if none!\n",
    "# (~torch.isfinite(X_train_tfm)).sum().item(),(~torch.isfinite(X_valid_tfm)).sum().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save these expensive features.\n",
    "torch.save(X_train_tfm,DATA/'X_train_tfm')\n",
    "torch.save(X_valid_tfm,DATA/'X_valid_tfm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Reload features later without recalculating.\n",
    "# X_valid_tfm = torch.load(DATA/'X_valid_tfm').to(device)\n",
    "# X_train_tfm = torch.load(DATA/'X_train_tfm').to(device)\n",
    "# X_train = torch.load(DATA/'X_train')\n",
    "# y_train = torch.load(DATA/'y_train')\n",
    "# X_valid = torch.load(DATA/'X_valid')\n",
    "# y_valid = torch.load(DATA/'y_valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "callN = 12  #Visualize the features of this one sound sample.\n",
    "plt.hist(X_train_tfm.cpu()[callN,0::2])\n",
    "plt.title('Distribution of maxes')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(X_train_tfm.cpu()[callN,1::2])\n",
    "plt.title('Distribution of positive fractions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Appending the call length as an extra feature does NOT help accuracy.\n",
    "# L_train = np.array([torch.isfinite(c).sum().item() for c in X_train])\n",
    "# L_valid = np.array([torch.isfinite(c).sum().item() for c in X_valid])\n",
    "# L_train = npM0S1(L_train)\n",
    "# L_valid = npM0S1(L_valid)\n",
    "# X_train_tfm = torch.cat((X_train_tfm,torch.cuda.FloatTensor(L_train).unsqueeze(1)), dim=1)\n",
    "# X_valid_tfm = torch.cat((X_valid_tfm,torch.cuda.FloatTensor(L_valid).unsqueeze(1)), dim=1)\n",
    "# t(X_train_tfm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2️⃣ Apply a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RidgeClassifierCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now you apply a classifier of your choice. \n",
    "With RidgeClassifierCV in particular, there's no need to normalize the calculated features before passing them to the classifier, as it does it internally (if normalize is set to True as recommended by the authors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 1.00E-02  train: 0.97872  valid: 0.96019\n"
     ]
    }
   ],
   "source": [
    "ridge = RidgeClassifierCV(alphas=np.logspace(-8, 8, 17), normalize=True, fit_intercept=True)\n",
    "ridge.fit(X_train_tfm.cpu(), y_train)\n",
    "\n",
    "print('alpha: {:.2E}  train: {:.5f}  valid: {:.5f}'.format(ridge.alpha_, \n",
    "                                                           ridge.score(X_train_tfm.cpu(), y_train[:len(X_train_tfm)]), \n",
    "                                                           ridge.score(X_valid_tfm.cpu(), y_valid[:len(X_valid_tfm)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's do some familiar machine learning. I initially tried to bring the training into fastai in order to use its many conveniences. But I found that my code which once worked a few months ago now fails. After wasting far too much time debugging, it was faster and simpler to write a training loop directly in PyTorch. And as it turns out, that loop is many many times faster going through fastai!\n",
    "\n",
    "YMMV of course. The fastai code appears further below. You're encouraged to fix it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the two letter labels into integers that PyTorch can use. Place on device.\n",
    "unames,y_trainN = np.unique(y_train, return_inverse=True)\n",
    "unames,y_validN = np.unique(y_valid, return_inverse=True)\n",
    "\n",
    "ttargets = torch.cuda.LongTensor(y_trainN).to(device)\n",
    "vtargets = torch.cuda.LongTensor(y_validN).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize inputs per feature.\n",
    "# I don't think it's understood why this helps, but it does empirically.\n",
    "# In this particular example, it adds about 1% to the accuracy.\n",
    "f_mean = X_train_tfm.mean(dim=0, keepdims=True)\n",
    "f_std = X_train_tfm.std(dim=0, keepdims=True) +1e-6\n",
    "\n",
    "X_train_tfm = (X_train_tfm - f_mean) / f_std\n",
    "X_valid_tfm = (X_valid_tfm - f_mean) / f_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model is simply one Linear layer with weights and biases.\n",
    "trainModel = nn.Sequential(nn.Linear(X_train_tfm.shape[-1],len(unames))).cuda()\n",
    "\n",
    "import torch.optim as optim \n",
    "\n",
    "# optimizer = optim.Adam(trainModel.parameters(), lr=.005, weight_decay=0)?\n",
    "optimizer = optim.SGD(trainModel.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   training loss   train accuracy  validation loss    valid accuracy\n",
      "0 2.305133581161499 0.08150308579206467 2.2927215099334717 0.08510638028383255\n",
      "200 0.27223441004753113 0.9138640761375427 0.3123724162578583 0.9039121270179749\n",
      "400 0.22141903638839722 0.9301646947860718 0.26923468708992004 0.9196979999542236\n",
      "600 0.1944897621870041 0.9414893388748169 0.24668945372104645 0.9320521354675293\n",
      "800 0.17667122185230255 0.9468084573745728 0.231561541557312 0.9327384829521179\n",
      "1000 0.16354061663150787 0.951956033706665 0.22026850283145905 0.9347975254058838\n",
      "1200 0.1532295197248459 0.9555593729019165 0.21132679283618927 0.9368565082550049\n",
      "1400 0.14479172229766846 0.9581331014633179 0.2039727419614792 0.9375428557395935\n",
      "1600 0.13768614828586578 0.9596773982048035 0.19776062667369843 0.940288245677948\n",
      "1800 0.13157491385936737 0.9627659320831299 0.19240802526474 0.9396018981933594\n",
      "2000 0.12623237073421478 0.9643102288246155 0.18772488832473755 0.940288245677948\n",
      "2200 0.12150037288665771 0.9646533727645874 0.18357722461223602 0.9430336356163025\n",
      "2400 0.11726389080286026 0.9660260677337646 0.17986705899238586 0.9437199234962463\n",
      "2600 0.11343660950660706 0.9668839573860168 0.17652052640914917 0.9450926184654236\n",
      "2800 0.10995251685380936 0.9687713980674744 0.1734805405139923 0.9450926184654236\n",
      "3000 0.10675986856222153 0.97031569480896 0.1707019954919815 0.9457789659500122\n",
      "3200 0.10381758213043213 0.9711736440658569 0.1681489795446396 0.9478380084037781\n",
      "3400 0.10109250247478485 0.9720315337181091 0.16579225659370422 0.9485243558883667\n",
      "3600 0.0985574796795845 0.973232626914978 0.1636076718568802 0.9485243558883667\n",
      "3800 0.09619006514549255 0.9735758304595947 0.16157524287700653 0.9492107033729553\n",
      "4000 0.09397143870592117 0.9747769236564636 0.15967820584774017 0.9485243558883667\n",
      "4200 0.09188574552536011 0.9756348133087158 0.15790218114852905 0.949897050857544\n",
      "4400 0.08991952985525131 0.9766643643379211 0.15623503923416138 0.9505833387374878\n",
      "4600 0.08806116133928299 0.9771791100502014 0.15466618537902832 0.9505833387374878\n",
      "4800 0.08630067110061646 0.9783802032470703 0.15318645536899567 0.9505833387374878\n",
      "5000 0.08462934195995331 0.9785518050193787 0.15178783237934113 0.9505833387374878\n",
      "5200 0.08303962647914886 0.9788949489593506 0.1504632979631424 0.9512696862220764\n",
      "5400 0.08152478188276291 0.9792381525039673 0.14920654892921448 0.951956033706665\n",
      "5600 0.08007896691560745 0.9799244999885559 0.14801213145256042 0.9533287286758423\n",
      "5800 0.07869694381952286 0.9804392457008362 0.14687517285346985 0.9533287286758423\n",
      "6000 0.07737399637699127 0.9806108474731445 0.1457912027835846 0.9533287286758423\n",
      "6200 0.07610597461462021 0.9807823896408081 0.14475630223751068 0.9533287286758423\n",
      "6400 0.07488908618688583 0.9818119406700134 0.14376696944236755 0.9560741186141968\n",
      "6600 0.07371993362903595 0.981983482837677 0.14281998574733734 0.9560741186141968\n",
      "6800 0.07259538024663925 0.9823266863822937 0.1419125646352768 0.9567604660987854\n",
      "7000 0.0715126320719719 0.9823266863822937 0.14104203879833221 0.9567604660987854\n",
      "7200 0.07046908140182495 0.9826698303222656 0.14020609855651855 0.9567604660987854\n",
      "7400 0.06946234405040741 0.982841432094574 0.13940253853797913 0.9574467539787292\n",
      "7600 0.06849026679992676 0.9835277795791626 0.1386295109987259 0.9574467539787292\n",
      "7800 0.06755082309246063 0.9838709235191345 0.13788512349128723 0.9574467539787292\n",
      "8000 0.06664218008518219 0.9840425252914429 0.13716772198677063 0.9574467539787292\n",
      "8200 0.06576262414455414 0.9842141270637512 0.13647592067718506 0.9581331014633179\n",
      "8400 0.06491057574748993 0.9845572710037231 0.13580821454524994 0.9588194489479065\n",
      "8600 0.06408456712961197 0.9845572710037231 0.135163351893425 0.9588194489479065\n",
      "8800 0.06328326463699341 0.9849004745483398 0.1345401108264923 0.9588194489479065\n",
      "9000 0.06250540167093277 0.9850720167160034 0.13393747806549072 0.9588194489479065\n",
      "9200 0.06174977496266365 0.9854152202606201 0.1333543360233307 0.9588194489479065\n",
      "9400 0.06101536378264427 0.985758364200592 0.13278979063034058 0.9595057964324951\n",
      "9600 0.06030109152197838 0.9859299659729004 0.13224288821220398 0.9595057964324951\n",
      "9800 0.05960606038570404 0.9861015677452087 0.1317128688097 0.9601921439170837\n",
      "10000 0.05892938748002052 0.9862731099128723 0.1311989277601242 0.9601921439170837\n"
     ]
    }
   ],
   "source": [
    "# PyTorch training loop.\n",
    "\n",
    "print('epoch   training loss   train accuracy  validation loss    valid accuracy')\n",
    "for epoch in range(10001):  # loop over the dataset multiple times\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + step\n",
    "    tpreds = trainModel(X_train_tfm)\n",
    "    tloss = loss_fn(tpreds, ttargets)\n",
    "    with torch.no_grad():\n",
    "        vpreds = trainModel(X_valid_tfm)\n",
    "        vloss = loss_fn(vpreds, vtargets)\n",
    "    if epoch%200 == 0:\n",
    "        print(epoch,tloss.item(),accuracyCopy(tpreds,ttargets).item(),vloss.item(), accuracyCopy(vpreds,vtargets).item())\n",
    "    tloss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = trainModel[0].weight.data\n",
    "wsave = w.clone()  #Save a copy in case of screw ups.\n",
    "\n",
    "# w = torch.tensor(ridge.coef_)  #Alternatively, use the weights that the RidgeClassifier found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#This plot suggests that many of the ROCKET features are not used for classification.\n",
    "#What if the unused features were removed, or replaced by other random conv1d's?\n",
    "_ = plt.hist(w.norm(dim=0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Let's get these ROCKET features into fastai (v1).\n",
    "To do this, we will define DataSets and DataLoaders for the ROCKET features, then a Databunch, and Learner to use fastai.\n",
    "\n",
    "Tensor X_train_tfm, etc. are already in the proper format to give to the model. They even fit into GPU memory as a single batch. It bothers me that DataSet breaks the features into individual samples and DataLoader reassembles them back into batches. Perhaps a smart person can figure out a more efficient way to get the features into fastai.\n",
    "\n",
    "In the meantime, it's the price of the convenience of abstraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ROCKETDataset(Dataset):\n",
    "    def __init__(self, audioFeatures, labels):\n",
    "        self.audioFeatures = audioFeatures\n",
    "        self.labels = labels\n",
    " \n",
    "    def __len__(self):\n",
    "        return len(self.audioFeatures)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.audioFeatures[idx],self.labels[idx]\n",
    "\n",
    "#I defined this \"attribute\" only to work around an error thrown by fastai.\n",
    "#I cannot figure out what fastai is trying to do.\n",
    "    def init_kwargs(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDS = ROCKETDataset(X_train_tfm,ttargets)\n",
    "validDS = ROCKETDataset(X_valid_tfm,vtargets)\n",
    "# trainDS = TensorDataset(X_train_tfm,ttargets)  #PyTorch utility for handling this exact situation.\n",
    "# validDS = TensorDataset(X_valid_tfm,vtargets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My GPU can handle the whole epoch at once, thus the full batch size.\n",
    "trainDL = DataLoader(trainDS, batch_size=len(trainDS), shuffle=True, num_workers=0, pin_memory=False)\n",
    "validDL = DataLoader(validDS, batch_size=len(validDS), shuffle=True, num_workers=0, pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(cuda:0)[5828, 2000]<float32> Tensor(cuda:0)[5828]<int64>\n",
      "Tensor(cuda:0)[1457, 2000]<float32> Tensor(cuda:0)[1457]<int64>\n"
     ]
    }
   ],
   "source": [
    "# Works?\n",
    "for tbatch,ttarget in trainDL:\n",
    "    print(t(tbatch),t(ttarget))\n",
    "for vbatch,vtarget in validDL:\n",
    "    print(t(vbatch),t(vtarget))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.basics import *\n",
    "data = DataBunch(trainDL,validDL)  # Fails unless init_kwargs(self) is defined in the DataSet.\n",
    "learn = Learner(data, trainModel, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This code used to suppress the progress bar. Now throws error.\n",
    "# from fastai.utils.mod_display import *\n",
    "# with progress_disabled_ctx(learn) as learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.058926</td>\n",
       "      <td>0.131031</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.058836</td>\n",
       "      <td>0.130965</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.058756</td>\n",
       "      <td>0.130901</td>\n",
       "      <td>0.960878</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.058679</td>\n",
       "      <td>0.130971</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.058594</td>\n",
       "      <td>0.130859</td>\n",
       "      <td>0.959506</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.058508</td>\n",
       "      <td>0.130496</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.058416</td>\n",
       "      <td>0.130208</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.058320</td>\n",
       "      <td>0.130149</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.058214</td>\n",
       "      <td>0.130283</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.058101</td>\n",
       "      <td>0.130156</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.057979</td>\n",
       "      <td>0.129663</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.057846</td>\n",
       "      <td>0.129187</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.057702</td>\n",
       "      <td>0.129053</td>\n",
       "      <td>0.959506</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.057546</td>\n",
       "      <td>0.129055</td>\n",
       "      <td>0.960878</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.057377</td>\n",
       "      <td>0.128733</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.057196</td>\n",
       "      <td>0.128102</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.056999</td>\n",
       "      <td>0.127659</td>\n",
       "      <td>0.960192</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.056788</td>\n",
       "      <td>0.127534</td>\n",
       "      <td>0.961565</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.056562</td>\n",
       "      <td>0.127148</td>\n",
       "      <td>0.960878</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.056321</td>\n",
       "      <td>0.126210</td>\n",
       "      <td>0.961565</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.056064</td>\n",
       "      <td>0.126139</td>\n",
       "      <td>0.961565</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.055789</td>\n",
       "      <td>0.125454</td>\n",
       "      <td>0.962251</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.055498</td>\n",
       "      <td>0.124783</td>\n",
       "      <td>0.961565</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>0.055192</td>\n",
       "      <td>0.124658</td>\n",
       "      <td>0.964310</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>0.054875</td>\n",
       "      <td>0.124686</td>\n",
       "      <td>0.962938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.054559</td>\n",
       "      <td>0.124797</td>\n",
       "      <td>0.964310</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.054267</td>\n",
       "      <td>0.124180</td>\n",
       "      <td>0.963624</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.053931</td>\n",
       "      <td>0.123549</td>\n",
       "      <td>0.962938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.053575</td>\n",
       "      <td>0.123684</td>\n",
       "      <td>0.964310</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.053238</td>\n",
       "      <td>0.121842</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.052854</td>\n",
       "      <td>0.124107</td>\n",
       "      <td>0.963624</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.052492</td>\n",
       "      <td>0.121898</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>0.052110</td>\n",
       "      <td>0.120354</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>0.051702</td>\n",
       "      <td>0.123776</td>\n",
       "      <td>0.962251</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.051318</td>\n",
       "      <td>0.120472</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.050898</td>\n",
       "      <td>0.119330</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.050471</td>\n",
       "      <td>0.122444</td>\n",
       "      <td>0.963624</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>0.050063</td>\n",
       "      <td>0.120686</td>\n",
       "      <td>0.967742</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>0.049637</td>\n",
       "      <td>0.117999</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.049211</td>\n",
       "      <td>0.125221</td>\n",
       "      <td>0.963624</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.048834</td>\n",
       "      <td>0.121423</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>0.048427</td>\n",
       "      <td>0.117609</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>0.047991</td>\n",
       "      <td>0.121153</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>0.047574</td>\n",
       "      <td>0.124391</td>\n",
       "      <td>0.962938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>0.047182</td>\n",
       "      <td>0.119348</td>\n",
       "      <td>0.962251</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.046746</td>\n",
       "      <td>0.116767</td>\n",
       "      <td>0.964310</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>0.046305</td>\n",
       "      <td>0.122006</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>0.045877</td>\n",
       "      <td>0.120114</td>\n",
       "      <td>0.962251</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>0.045449</td>\n",
       "      <td>0.117964</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>0.045002</td>\n",
       "      <td>0.119383</td>\n",
       "      <td>0.962938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.044558</td>\n",
       "      <td>0.117945</td>\n",
       "      <td>0.961565</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>0.044121</td>\n",
       "      <td>0.120151</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>0.043695</td>\n",
       "      <td>0.116842</td>\n",
       "      <td>0.962938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.043252</td>\n",
       "      <td>0.118451</td>\n",
       "      <td>0.964310</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>0.042808</td>\n",
       "      <td>0.118503</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.042373</td>\n",
       "      <td>0.116012</td>\n",
       "      <td>0.962251</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>0.041942</td>\n",
       "      <td>0.117885</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>0.041509</td>\n",
       "      <td>0.118555</td>\n",
       "      <td>0.964310</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>0.041078</td>\n",
       "      <td>0.115707</td>\n",
       "      <td>0.964310</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>0.040654</td>\n",
       "      <td>0.118289</td>\n",
       "      <td>0.962938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.040246</td>\n",
       "      <td>0.117537</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>0.039861</td>\n",
       "      <td>0.124327</td>\n",
       "      <td>0.961565</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>0.039536</td>\n",
       "      <td>0.130521</td>\n",
       "      <td>0.962251</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>0.039382</td>\n",
       "      <td>0.123796</td>\n",
       "      <td>0.959506</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.039064</td>\n",
       "      <td>0.115681</td>\n",
       "      <td>0.962938</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.038655</td>\n",
       "      <td>0.119536</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.038312</td>\n",
       "      <td>0.119789</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.037933</td>\n",
       "      <td>0.117704</td>\n",
       "      <td>0.961565</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>0.037554</td>\n",
       "      <td>0.118011</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>0.037193</td>\n",
       "      <td>0.119874</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.036818</td>\n",
       "      <td>0.119286</td>\n",
       "      <td>0.964310</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>0.036451</td>\n",
       "      <td>0.116534</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.036093</td>\n",
       "      <td>0.118380</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.035725</td>\n",
       "      <td>0.119386</td>\n",
       "      <td>0.964310</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.035364</td>\n",
       "      <td>0.115809</td>\n",
       "      <td>0.963624</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.035007</td>\n",
       "      <td>0.115390</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>0.034643</td>\n",
       "      <td>0.118240</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.034294</td>\n",
       "      <td>0.116637</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>0.033937</td>\n",
       "      <td>0.115667</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.033592</td>\n",
       "      <td>0.116556</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.033247</td>\n",
       "      <td>0.117341</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>0.032906</td>\n",
       "      <td>0.116376</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>0.032572</td>\n",
       "      <td>0.115894</td>\n",
       "      <td>0.964996</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>0.032238</td>\n",
       "      <td>0.116778</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>0.031911</td>\n",
       "      <td>0.116623</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.031587</td>\n",
       "      <td>0.116046</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>0.031268</td>\n",
       "      <td>0.115877</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>0.030952</td>\n",
       "      <td>0.115902</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>0.030641</td>\n",
       "      <td>0.116114</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>0.030334</td>\n",
       "      <td>0.116094</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.030031</td>\n",
       "      <td>0.115965</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.029732</td>\n",
       "      <td>0.115696</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>0.029437</td>\n",
       "      <td>0.116036</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>0.029147</td>\n",
       "      <td>0.116350</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.028860</td>\n",
       "      <td>0.116122</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.028577</td>\n",
       "      <td>0.115811</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>0.028298</td>\n",
       "      <td>0.116047</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>0.028023</td>\n",
       "      <td>0.116340</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.027751</td>\n",
       "      <td>0.116163</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>0.027484</td>\n",
       "      <td>0.115897</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.027220</td>\n",
       "      <td>0.115961</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>0.026960</td>\n",
       "      <td>0.116160</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>0.026703</td>\n",
       "      <td>0.116163</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.026450</td>\n",
       "      <td>0.116157</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.026201</td>\n",
       "      <td>0.116216</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.025955</td>\n",
       "      <td>0.116236</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.025713</td>\n",
       "      <td>0.116138</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.025474</td>\n",
       "      <td>0.116153</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.025238</td>\n",
       "      <td>0.116323</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.025006</td>\n",
       "      <td>0.116426</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.024776</td>\n",
       "      <td>0.116312</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>0.024551</td>\n",
       "      <td>0.116159</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>0.024328</td>\n",
       "      <td>0.116162</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>0.024108</td>\n",
       "      <td>0.116301</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.023892</td>\n",
       "      <td>0.116383</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>0.023679</td>\n",
       "      <td>0.116340</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>0.023469</td>\n",
       "      <td>0.116275</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.023261</td>\n",
       "      <td>0.116274</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.023057</td>\n",
       "      <td>0.116334</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.022856</td>\n",
       "      <td>0.116395</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.022657</td>\n",
       "      <td>0.116430</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.022462</td>\n",
       "      <td>0.116443</td>\n",
       "      <td>0.967056</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.022269</td>\n",
       "      <td>0.116446</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>0.022079</td>\n",
       "      <td>0.116440</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.021892</td>\n",
       "      <td>0.116432</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.021707</td>\n",
       "      <td>0.116444</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.021526</td>\n",
       "      <td>0.116477</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.021346</td>\n",
       "      <td>0.116512</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.021170</td>\n",
       "      <td>0.116529</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.020996</td>\n",
       "      <td>0.116522</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.020825</td>\n",
       "      <td>0.116511</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>0.020656</td>\n",
       "      <td>0.116515</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.020490</td>\n",
       "      <td>0.116541</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.020326</td>\n",
       "      <td>0.116574</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.020165</td>\n",
       "      <td>0.116598</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.020006</td>\n",
       "      <td>0.116609</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.019849</td>\n",
       "      <td>0.116615</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>0.019695</td>\n",
       "      <td>0.116624</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.019543</td>\n",
       "      <td>0.116642</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>0.019394</td>\n",
       "      <td>0.116666</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.019247</td>\n",
       "      <td>0.116688</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.019102</td>\n",
       "      <td>0.116704</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.018959</td>\n",
       "      <td>0.116714</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>0.018819</td>\n",
       "      <td>0.116724</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.018681</td>\n",
       "      <td>0.116736</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.018545</td>\n",
       "      <td>0.116751</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.018411</td>\n",
       "      <td>0.116765</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.018279</td>\n",
       "      <td>0.116776</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>0.018149</td>\n",
       "      <td>0.116782</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.018021</td>\n",
       "      <td>0.116785</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.017896</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.966369</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.017772</td>\n",
       "      <td>0.116794</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>0.017651</td>\n",
       "      <td>0.116805</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.017531</td>\n",
       "      <td>0.116821</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>0.017413</td>\n",
       "      <td>0.116838</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.017298</td>\n",
       "      <td>0.116855</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.017184</td>\n",
       "      <td>0.116869</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>0.017072</td>\n",
       "      <td>0.116879</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>0.016962</td>\n",
       "      <td>0.116884</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.016854</td>\n",
       "      <td>0.116887</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.016748</td>\n",
       "      <td>0.116888</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.016643</td>\n",
       "      <td>0.116890</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.016541</td>\n",
       "      <td>0.116893</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.016440</td>\n",
       "      <td>0.116898</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>0.016340</td>\n",
       "      <td>0.116906</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.016243</td>\n",
       "      <td>0.116914</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>0.016147</td>\n",
       "      <td>0.116924</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.016053</td>\n",
       "      <td>0.116934</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.015961</td>\n",
       "      <td>0.116943</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>0.116951</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.015781</td>\n",
       "      <td>0.116958</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>0.015694</td>\n",
       "      <td>0.116963</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.015608</td>\n",
       "      <td>0.116968</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.015524</td>\n",
       "      <td>0.116971</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.015441</td>\n",
       "      <td>0.116974</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.015360</td>\n",
       "      <td>0.116976</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>0.015280</td>\n",
       "      <td>0.116978</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>0.015202</td>\n",
       "      <td>0.116979</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.015125</td>\n",
       "      <td>0.116981</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.015050</td>\n",
       "      <td>0.116982</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.014976</td>\n",
       "      <td>0.116983</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.014904</td>\n",
       "      <td>0.116985</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.014833</td>\n",
       "      <td>0.116986</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>0.014763</td>\n",
       "      <td>0.116988</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.014695</td>\n",
       "      <td>0.116989</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.014628</td>\n",
       "      <td>0.116990</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>0.014562</td>\n",
       "      <td>0.116992</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.014498</td>\n",
       "      <td>0.116993</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.014435</td>\n",
       "      <td>0.116994</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.014373</td>\n",
       "      <td>0.116994</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.014313</td>\n",
       "      <td>0.116995</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.014254</td>\n",
       "      <td>0.116996</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.014196</td>\n",
       "      <td>0.116996</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.014139</td>\n",
       "      <td>0.116997</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.014083</td>\n",
       "      <td>0.116997</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.014029</td>\n",
       "      <td>0.116997</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.013975</td>\n",
       "      <td>0.116997</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.013923</td>\n",
       "      <td>0.116997</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.013872</td>\n",
       "      <td>0.116997</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.013822</td>\n",
       "      <td>0.116997</td>\n",
       "      <td>0.965683</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "    for i in range(1):\n",
    "        learn.fit_one_cycle(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The end. 97.3% accuracy for this run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
